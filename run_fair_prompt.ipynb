{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-15 14:41:11 config.py:433] Custom all-reduce kernels are temporarily disabled due to stability issues. We will re-enable them once the issues are resolved.\n",
      "2024-04-15 14:41:14,099\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "INFO 04-15 14:41:15 llm_engine.py:87] Initializing an LLM engine with config: model='/data/MODELS/llama-2-7b', tokenizer='/data/MODELS/llama-2-7b', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 04-15 14:41:32 llm_engine.py:357] # GPU blocks: 3400, # CPU blocks: 1024\n",
      "INFO 04-15 14:41:33 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-15 14:41:33 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=2652735)\u001b[0m INFO 04-15 14:41:33 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=2652735)\u001b[0m INFO 04-15 14:41:33 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-15 14:41:38 model_runner.py:756] Graph capturing finished in 5 secs.\n",
      "\u001b[36m(RayWorkerVllm pid=2652735)\u001b[0m INFO 04-15 14:41:38 model_runner.py:756] Graph capturing finished in 5 secs.\n",
      "PROMPT EXAMPLE: \n",
      "Review: a peculiar misfire that even tunney ca n't save .\n",
      "Sentiment: Negative\n",
      "\n",
      "Review: no movement , no yuks , not much of anything .\n",
      "Sentiment:\n",
      "\n",
      "Processed prompts: 100%|████████████████████| 1821/1821 [00:28<00:00, 64.09it/s]\n",
      "Dataset: sst2, Accuracy: 0.8847\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=\"0,1\" python fair_prompt.py --m \"/data/MODELS/llama-2-7b\" --tensor_parallel_size 2 --num_shots 12 --dataset sst2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-15 14:43:38 config.py:433] Custom all-reduce kernels are temporarily disabled due to stability issues. We will re-enable them once the issues are resolved.\n",
      "2024-04-15 14:43:40,291\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "INFO 04-15 14:43:41 llm_engine.py:87] Initializing an LLM engine with config: model='/data/MODELS/llama-2-7b', tokenizer='/data/MODELS/llama-2-7b', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 04-15 14:43:58 llm_engine.py:357] # GPU blocks: 3400, # CPU blocks: 1024\n",
      "INFO 04-15 14:43:59 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-15 14:43:59 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=2658756)\u001b[0m INFO 04-15 14:43:59 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=2658756)\u001b[0m INFO 04-15 14:43:59 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-15 14:44:04 model_runner.py:756] Graph capturing finished in 5 secs.\n",
      "\u001b[36m(RayWorkerVllm pid=2658756)\u001b[0m INFO 04-15 14:44:04 model_runner.py:756] Graph capturing finished in 5 secs.\n",
      "PROMPT EXAMPLE: \n",
      "Classify the news articles into the categories of World, Sports, Business, and Technology.\n",
      "\n",
      "Article: Sony-led consortium inks MGM purchase deal:. Business India Los Angeles, Sep 24 : After months of wrangling, a consortium led by Sony Corp has signed a definitive deal to buy the famous Hollywood studio MGM, Xinhua reports.\n",
      "Answer: Business\n",
      "\n",
      "Article: Opec  'ready with spare capacity'. Oil ministers of Opec countries say they have the capacity to pump more oil after crude prices hit fresh highs last week. \n",
      "Answer: Business\n",
      "\n",
      "Article: Fears for T N pension after talks. Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\n",
      "Answer:\n",
      "\n",
      "Processed prompts: 100%|████████████████████| 7600/7600 [05:15<00:00, 24.13it/s]\n",
      "Dataset: agnews, Accuracy: 0.8914\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=\"0,1\" python fair_prompt.py --m \"/data/MODELS/llama-2-7b\" --tensor_parallel_size 2 --num_shots 12 --dataset agnews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-15 14:49:45 config.py:433] Custom all-reduce kernels are temporarily disabled due to stability issues. We will re-enable them once the issues are resolved.\n",
      "2024-04-15 14:49:47,539\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "INFO 04-15 14:49:48 llm_engine.py:87] Initializing an LLM engine with config: model='/data/MODELS/llama-2-7b', tokenizer='/data/MODELS/llama-2-7b', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 04-15 14:50:04 llm_engine.py:357] # GPU blocks: 3400, # CPU blocks: 1024\n",
      "INFO 04-15 14:50:06 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-15 14:50:06 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=2664808)\u001b[0m INFO 04-15 14:50:06 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=2664808)\u001b[0m INFO 04-15 14:50:06 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-15 14:50:10 model_runner.py:756] Graph capturing finished in 4 secs.\n",
      "\u001b[36m(RayWorkerVllm pid=2664808)\u001b[0m INFO 04-15 14:50:10 model_runner.py:756] Graph capturing finished in 4 secs.\n",
      "PROMPT EXAMPLE: \n",
      "Classify the questions based on whether their answer type is a Number, Location, Person, Description, Entity, or Abbreviation.\n",
      "\n",
      "Question: Where did the sport of caber-tossing originate?\n",
      "Answer Type: Location\n",
      "\n",
      "Question: How far is it from Denver to Aspen?\n",
      "Answer Type:\n",
      "\n",
      "Processed prompts: 100%|██████████████████████| 500/500 [00:07<00:00, 71.30it/s]\n",
      "Dataset: trec, Accuracy: 0.7360\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=\"0,1\" python fair_prompt.py --m \"/data/MODELS/llama-2-7b\" --tensor_parallel_size 2 --num_shots 12 --dataset trec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-15 14:50:30 config.py:433] Custom all-reduce kernels are temporarily disabled due to stability issues. We will re-enable them once the issues are resolved.\n",
      "2024-04-15 14:50:32,264\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "INFO 04-15 14:50:33 llm_engine.py:87] Initializing an LLM engine with config: model='/data/MODELS/llama-2-7b', tokenizer='/data/MODELS/llama-2-7b', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 04-15 14:50:50 llm_engine.py:357] # GPU blocks: 3400, # CPU blocks: 1024\n",
      "INFO 04-15 14:50:51 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-15 14:50:51 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=2670773)\u001b[0m INFO 04-15 14:50:51 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=2670773)\u001b[0m INFO 04-15 14:50:51 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=2670773)\u001b[0m INFO 04-15 14:50:55 model_runner.py:756] Graph capturing finished in 4 secs.\n",
      "INFO 04-15 14:50:55 model_runner.py:756] Graph capturing finished in 4 secs.\n",
      "PROMPT EXAMPLE: \n",
      " The voluntary recall is considered a Class II recall since it covers products that might cause a temporary health problem or pose only a slight threat of a serious nature, the FDA said.\n",
      "question: A Class II recall covers products that might cause a temporary health problem. True or False?\n",
      "answer: True\n",
      "\n",
      " Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation.\n",
      "question: Christopher Reeve had an accident. True or False?\n",
      "answer:\n",
      "\n",
      "Processed prompts: 100%|██████████████████████| 277/277 [00:10<00:00, 26.17it/s]\n",
      "Dataset: rte, Accuracy: 0.6895\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=\"0,1\" python fair_prompt.py --m \"/data/MODELS/llama-2-7b\" --tensor_parallel_size 2 --num_shots 12 --dataset rte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-15 14:51:16 config.py:433] Custom all-reduce kernels are temporarily disabled due to stability issues. We will re-enable them once the issues are resolved.\n",
      "2024-04-15 14:51:18,603\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "INFO 04-15 14:51:19 llm_engine.py:87] Initializing an LLM engine with config: model='/data/MODELS/llama-2-7b', tokenizer='/data/MODELS/llama-2-7b', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 04-15 14:51:36 llm_engine.py:357] # GPU blocks: 3400, # CPU blocks: 1024\n",
      "INFO 04-15 14:51:37 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-15 14:51:37 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=2676740)\u001b[0m INFO 04-15 14:51:37 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=2676740)\u001b[0m INFO 04-15 14:51:37 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-15 14:51:41 model_runner.py:756] Graph capturing finished in 4 secs.\n",
      "\u001b[36m(RayWorkerVllm pid=2676740)\u001b[0m INFO 04-15 14:51:41 model_runner.py:756] Graph capturing finished in 4 secs.\n",
      "PROMPT EXAMPLE: \n",
      "Sentence: The dog barked its way out of the room.\n",
      "Hypothesis: the sentence is grammatical, true or false? true\n",
      "\n",
      "Sentence: Bill whistled his way past the house.\n",
      "Hypothesis: the sentence is grammatical, true or false? true\n",
      "\n",
      "Sentence: The weights made the rope stretch over the pulley.\n",
      "Hypothesis: the sentence is grammatical, true or false?\n",
      "\n",
      "Processed prompts: 100%|██████████████████████| 200/200 [00:03<00:00, 50.27it/s]\n",
      "Dataset: cola, Accuracy: 0.6150\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=\"0,1\" python fair_prompt.py --m \"/data/MODELS/llama-2-7b\" --tensor_parallel_size 2 --num_shots 12 --dataset cola"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
